id: prepare_database
learningObjectives:
  - Set up the BigQuery dataset for seismic data analysis.
hints:
  - Navigate to the BigQuery page in the GCP console to create a dataset.
startFlow:
  do:
    - actionId: bot_message
      params:
        person: lucca
        messages:
          - text: >
              We need a centralized location to store and analyze seismic data. BigQuery
              provides a scalable and efficient way to handle large datasets, making it
              ideal for our analytical needs.
          - text: :instruction[Create a dataset named 'SeismicAnalysis' in BigQuery] to store insights.
          - text:
              Ping me in our secure channel if any tremors are detectedâ€”or if you've
              completed the setup!
    - actionId: ready_message
      params:
        person: lucca
trigger:
  type: user_ready_response
  flowNode:
    do:
      - actionId: gcp_api_request
        name: gcp_db_exists
        params:
          path: "bigquery/v2/projects/${user.integrations.gcp.project_id}/datasets/SeismicAnalysis"
    if:
      conditions:
        - conditionId: text_contains_strings
          params:
            text: ${outputs.gcp_db_exists?.data?.id}
            strings:
              - SeismicAnalysis
      then:
        do:
          - actionId: bot_message
            params:
              person: lucca
              messages:
                - text: "The dataset 'SeismicAnalysis' has been successfully created in BigQuery."
          - actionId: finish_step
      else:
        do:
          - actionId: bot_message
            params:
              person: lucca
              messages:
                - text: "Couldn't find the dataset 'SeismicAnalysis' in BigQuery under the Wilco project. Please create the dataset as instructed."
          - actionId: ready_message
            params:
              person: lucca
